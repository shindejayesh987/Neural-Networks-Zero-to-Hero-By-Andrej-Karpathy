{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shindejayesh987/Neural-Networks-Zero-to-Hero-By-Andrej-Karpathy/blob/main/wavenet_part5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xzz6ts_Ks-S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytEFZQAtKs-U"
      },
      "source": [
        "# 1- Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIaTXQyTKs-V",
        "outputId": "a85b3170-cafc-4505-f8f7-3822740dcc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
            "32033\n"
          ]
        }
      ],
      "source": [
        "words = open(\"/content/names.txt\", \"r\").read().splitlines()\n",
        "print(words[:8])\n",
        "print(len(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SU-XdyGKs-W",
        "outputId": "2001bc24-e4fb-492c-9004-2112f26c0934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(\"\".join(words))))\n",
        "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
        "stoi[\".\"] = 0\n",
        "itos = {i: s for s, i in stoi.items()}\n",
        "vocab_size = len(stoi)\n",
        "\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWMYVMEkKs-X",
        "outputId": "d089b473-74c4-459a-9f3f-0fc95f45814d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "block_size = 3\n",
        "\n",
        "\n",
        "def build_dataset(words):\n",
        "\n",
        "    X, Y = [], []\n",
        "\n",
        "    for w in words:\n",
        "\n",
        "        context = [0] * block_size\n",
        "        for ch in w + '.':\n",
        "\n",
        "            ix = stoi[ch]\n",
        "\n",
        "            X.append(context)\n",
        "            Y.append(ix)\n",
        "\n",
        "            context = context[1:] + [ix]\n",
        "\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "    print(X.shape, Y.shape)\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13d8PBn9Ks-X",
        "outputId": "ec5bdfe4-50ac-4710-b186-867aaae516cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... ----> y\n",
            "..y ----> u\n",
            ".yu ----> h\n",
            "yuh ----> e\n",
            "uhe ----> n\n",
            "hen ----> g\n",
            "eng ----> .\n",
            "... ----> d\n",
            "..d ----> i\n",
            ".di ----> o\n",
            "dio ----> n\n",
            "ion ----> d\n",
            "ond ----> r\n",
            "ndr ----> e\n",
            "dre ----> .\n"
          ]
        }
      ],
      "source": [
        "for x, y in zip(Xtr[:15], Ytr[:15]):\n",
        "    print(\"\".join(itos[ix.item()] for ix in x), \"---->\", itos[y.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yyGNLf3Ks-X"
      },
      "outputs": [],
      "source": [
        "# Layers made in part 3\n",
        "class Linear:\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn((fan_in, fan_out))\n",
        "        self.weight /= fan_in ** 0.5\n",
        "        self.bias = torch.zeros((fan_out)) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            self.out += self.bias\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "        # buffers (trained while running `momentum update`)\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.training:\n",
        "            # batch mean\n",
        "            xmean = x.mean(0, keepdim=True)\n",
        "            # batch variance\n",
        "            xvar = x.var(0, keepdim=True)\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "\n",
        "        # update the buffers in training\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * \\\n",
        "                    self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * \\\n",
        "                    self.running_var + self.momentum * xvar\n",
        "\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "\n",
        "class Tanh:\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.tanh(x)\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVQorv_YKs-Y",
        "outputId": "9d3226db-9cf0-4847-8dfd-a1ceffc0111d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a21c0ba5e90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30JWLqMQKs-Y",
        "outputId": "9c3af4cf-385d-4fb1-cba8-83b45755d6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num parameters: 12097\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "\n",
        "C = torch.randn((vocab_size, n_embd))\n",
        "layers = [\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
        "    BatchNorm1d(n_hidden),\n",
        "    Tanh(),\n",
        "    Linear(n_hidden, vocab_size)\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1\n",
        "\n",
        "parameters = [C] + [p for l in layers for p in l.parameters()]\n",
        "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu8L2SGvKs-Y",
        "outputId": "89a56dbf-2b24-4bc6-d693-107a3332b965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 loss 3.2966105937957764\n"
          ]
        }
      ],
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xb]  # embed characters into vector space\n",
        "    x = emb.view((emb.shape[0], -1))  # flatten\n",
        "    for layer in layers:\n",
        "        x = layer(x)\n",
        "    # compute loss\n",
        "    loss = F.cross_entropy(x, Yb)\n",
        "\n",
        "    # backward pass\n",
        "    for layer in layers:\n",
        "        layer.out.retain_grad()\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    lr = 0.1 if i < 10000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data -= lr * p.grad\n",
        "\n",
        "    # track stats\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"step {i} loss {loss.item()}\")\n",
        "\n",
        "    lossi.append(loss.item())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa44YqG4Ks-Y"
      },
      "source": [
        "## 1.2 Fixing the Learning Rate Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "uD83zip0Ks-Y",
        "outputId": "cb20f2c7-1a3f-4096-e0fb-5f578b99b76a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[-1, 1000]' is invalid for input of size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b96c6e9704c2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1000]' is invalid for input of size 1"
          ]
        }
      ],
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1, keepdim=True).data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DREZuqEyKs-Z"
      },
      "source": [
        "# 2- Pytorchifying our code\n",
        "add `Embedding`, `Flatten` and `Sequential` Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Han519Ks-Z"
      },
      "source": [
        "## 2.1 Classes Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS6tssshKs-Z"
      },
      "outputs": [],
      "source": [
        "# Layers made in part 3\n",
        "class Linear:\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn((fan_in, fan_out))\n",
        "        self.weight /= fan_in ** 0.5\n",
        "        self.bias = torch.zeros((fan_out)) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            self.out += self.bias\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "        # buffers (trained while running `momentum update`)\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.training:\n",
        "            # batch mean\n",
        "            xmean = x.mean(0, keepdim=True)\n",
        "            # batch variance\n",
        "            xvar = x.var(0, keepdim=True)\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "\n",
        "        # update the buffers in training\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * \\\n",
        "                    self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * \\\n",
        "                    self.running_var + self.momentum * xvar\n",
        "\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "\n",
        "class Tanh:\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.tanh(x)\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "# ---------------- new ----------------\n",
        "\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = self.weight[x]\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "\n",
        "class Flatten:\n",
        "    def __call__(self, x):\n",
        "        self.out = x.view((x.shape[0], -1))\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "\n",
        "class Sequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [p for l in self.layers for p in l.parameters()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2dAjPitKs-Z"
      },
      "source": [
        "## 2.2 Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcUkEcZmKs-Z",
        "outputId": "8c365ccb-4e2c-42bf-8d32-cfa4eea5cd7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num parameters: 12097\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
        "    BatchNorm1d(n_hidden),\n",
        "    Tanh(),\n",
        "\n",
        "    Linear(n_hidden, vocab_size)\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
        "for p in parameters:\n",
        "    p.requires_grad_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKsVNC9tKs-a"
      },
      "source": [
        "## 2.3 Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6pfIVB6Ks-a",
        "outputId": "7ed74236-9531-4409-fb3c-8fb1258837fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 loss 3.631577253341675\n"
          ]
        }
      ],
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "update_to_data_ratio = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "    # forward pass is now simpler\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    lr = 0.1 if i < 10000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data -= lr * p.grad\n",
        "\n",
        "    # track stats\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"step {i} loss {loss.item()}\")\n",
        "\n",
        "    lossi.append(loss.item())\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhB3zMteKs-a"
      },
      "source": [
        "## 2.4 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwg6CrUAKs-a"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers:\n",
        "    layer.training = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vAofNpKKs-a",
        "outputId": "d5a1b247-d57c-4340-d5e4-88829b2ae691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 3.4516208171844482\n",
            "valid 3.4509992599487305\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def split_loss(split):\n",
        "    x, y = {\n",
        "        \"train\": (Xtr, Ytr),\n",
        "        \"valid\": (Xdev, Ydev),\n",
        "        \"test\": (Xte, Yte)\n",
        "    }[split]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "print(\"train\", split_loss(\"train\"))\n",
        "print(\"valid\", split_loss(\"valid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6dMs_O_Ks-a"
      },
      "source": [
        "## 2.5- Sample from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzQv1REtKs-b",
        "outputId": "def35bb6-69f6-438d-eb4b-6418bbff3721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oezwcqorwedcve\n",
            "xmin\n",
            "ejtzsgxiycvzkoycihmo\n",
            "zuzjwfhcspltyxcnrzifjkdaiymwjgbzcg\n",
            "cudt\n",
            "ssvlpzyuxedxxjpvdzjtrvwgwdcdjduoexe\n",
            "owp\n",
            "rnwnj\n",
            "fl\n",
            "qfouarko\n",
            "e\n",
            "mvomiknkdqfxlzya\n",
            "erlllyoohutgyisdomggurjbzbanruvtccvdwij\n",
            "slssfsqazlhwnkvggwkouuqxvwdgnosyjcgatowdsvqzwdfvwapsusxpkzkszqvlzcwdtitdfmiobkblwfrpsbvigvqawilrngbyqbddjexivtsifoucphhp\n",
            "zbrzqf\n",
            "pajwmybc\n",
            "cvxajrjbqgkwsjhvpcrdojhqcgl\n",
            "cfenecniyafpejhgzkqhltpchnsnyxqjewigdqiwdyouzxn\n",
            "fjehbkvopkjtneueuuaid\n",
            "uyxxovejhylbczebrpjviigagewuuhvjepahdajzlduxfyexjrlrpfbpiazcnersmabjaecoegmisoxobkpxopoddtbn\n"
          ]
        }
      ],
      "source": [
        "# sampling from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "        # Forward pass\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        ix = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "        # Shift the Context Window\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "        out.append(ix)\n",
        "\n",
        "    print(\"\".join(itos[i] for i in out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiUBw8O_Ks-b"
      },
      "source": [
        "# 3- Building the WaveNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe_Qn7fwKs-b"
      },
      "source": [
        "![dilated_casual_conv](../images/dilated_casual_conv.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6CR6nr3Ks-b"
      },
      "source": [
        "## 3.1 Changing Dataset blocksize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGb1IMEHKs-b",
        "outputId": "20110699-f646-4364-e9cd-ad13c6fef1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182580, 8]) torch.Size([182580])\n",
            "torch.Size([22767, 8]) torch.Size([22767])\n",
            "torch.Size([22799, 8]) torch.Size([22799])\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "block_size = 8\n",
        "\n",
        "\n",
        "def build_dataset(words):\n",
        "\n",
        "    X, Y = [], []\n",
        "\n",
        "    for w in words:\n",
        "\n",
        "        context = [0] * block_size\n",
        "        for ch in w + '.':\n",
        "\n",
        "            ix = stoi[ch]\n",
        "\n",
        "            X.append(context)\n",
        "            Y.append(ix)\n",
        "\n",
        "            context = context[1:] + [ix]\n",
        "\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "    print(X.shape, Y.shape)\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe6w8ooeKs-b",
        "outputId": "94a7b161-6c2c-4927-fca9-050bff1ef277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "........ ----> e\n",
            ".......e ----> b\n",
            "......eb ----> r\n",
            ".....ebr ----> i\n",
            "....ebri ----> m\n",
            "...ebrim ----> a\n",
            "..ebrima ----> .\n",
            "........ ----> h\n",
            ".......h ----> i\n",
            "......hi ----> l\n",
            ".....hil ----> t\n",
            "....hilt ----> o\n",
            "...hilto ----> n\n",
            "..hilton ----> .\n",
            "........ ----> j\n"
          ]
        }
      ],
      "source": [
        "for x, y in zip(Xtr[:15], Ytr[:15]):\n",
        "    print(\"\".join(itos[ix.item()] for ix in x), \"---->\", itos[y.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myFbbNLeKs-c"
      },
      "source": [
        "## 3.2 Initializing a normal network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNjrc1TGKs-c",
        "outputId": "cde6fca4-7df0-4608-adc1-be949e8cbd13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num parameters: 22097\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
        "    BatchNorm1d(n_hidden),\n",
        "    Tanh(),\n",
        "\n",
        "    Linear(n_hidden, vocab_size)\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
        "for p in parameters:\n",
        "    p.requires_grad_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8vn4ZhIKs-c"
      },
      "source": [
        "## 3.3 Implementing WaveNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdW1IrreKs-d"
      },
      "source": [
        "### 3.3.1 Shape Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d55kSTquKs-d",
        "outputId": "ac8e6399-6f8d-4fc7-fa11-3558be5822ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0, 20],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  8],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  1],\n",
              "        [ 0,  0,  0,  0, 18,  1, 17, 21],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# look at batch of 5 examples (it's 4 in the original video but I changed it to 5 to prevent confusion)\n",
        "ix = torch.randint(0, Xtr.shape[0], (5,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2g4LevjKs-d",
        "outputId": "d4fab3a7-00c2-40f4-e793-379275572542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding has output size of: torch.Size([5, 8, 10])\n",
            "Flatten has output size of: torch.Size([5, 80])\n",
            "Linear has output size of: torch.Size([5, 200])\n",
            "BatchNorm1d has output size of: torch.Size([5, 200])\n",
            "Tanh has output size of: torch.Size([5, 200])\n",
            "Linear has output size of: torch.Size([5, 27])\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "    print(f\"{layer.__class__.__name__} has output size of: {layer.out.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrZc72qoKs-e"
      },
      "source": [
        "we don't want to process the 8 characters at the same time\n",
        "```\n",
        "1 2 3 4 5 6 7 8\n",
        "```\n",
        "but we want to process them in 4 groups of 2 characters in parallel\n",
        "```\n",
        "(1 2) (3 4) (5 6) (7 8)\n",
        "```\n",
        "\n",
        "so instead of multiplying `(5, 80) @ (80, 200) = (5, 200)` we want to multiply `(5, 4, 20) @ (20, 200) = (5, 4, 200)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J75ZzHTfKs-e",
        "outputId": "be56c0fb-4064-42af-c68a-7527f1304a79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# output of layer 0\n",
        "e = torch.randn(5, 8, 10)\n",
        "# contacenate even and odd (on character dimension) elements of the last dimension\n",
        "explicit = torch.cat([e[:, ::2, :], e[:, 1::2, :]], dim=2)\n",
        "# you can do the same using view\n",
        "implicit = e.view(5, 4, 20)\n",
        "\n",
        "(implicit == explicit).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9brkDS2Ks-e"
      },
      "source": [
        "### 3.3.2 - FlattenConsectutive Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0rvTTisKs-e"
      },
      "outputs": [],
      "source": [
        "# Reimplement Flatten\n",
        "class FlattenConsecutive:\n",
        "    def __init__(self, n):\n",
        "        # n is the number of consecutive elements we want (2 in our example)\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # in our example: B = 5, T = 8, C = 10\n",
        "        B, T, C = x.shape\n",
        "        # we want to convert X to (5, 4, 20)\n",
        "        x = x.view(B, T // self.n, C * self.n)\n",
        "\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.squeeze(1)\n",
        "\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZergjlaKs-f"
      },
      "source": [
        "### 3.3.3 - previous behavior using FlattenConsecutive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccrQ5XnnKs-f",
        "outputId": "db7740e0-7ed2-4eb3-b35f-5a7acbf553ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num parameters: 22097\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    # calling FlattenConsecutive(block_size) will return in the same previous behavior\n",
        "    FlattenConsecutive(block_size),\n",
        "\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
        "    BatchNorm1d(n_hidden),\n",
        "    Tanh(),\n",
        "\n",
        "    Linear(n_hidden, vocab_size)\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
        "for p in parameters:\n",
        "    p.requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1VpOBHqKs-f",
        "outputId": "bf5e4004-2d19-4cfb-faa0-2ccb7b1665ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0, 13, 15,  8,  1, 13],\n",
              "        [ 0,  0,  0,  0, 11,  1, 19,  9],\n",
              "        [ 0,  0,  0,  0,  0, 10,  1, 25],\n",
              "        [ 0,  0,  0,  0,  0, 18,  9,  8],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  4]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (5,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUsTmZLJKs-f",
        "outputId": "50882c42-f409-43c0-a802-21c833bc0e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding has output size of: torch.Size([5, 8, 10])\n",
            "FlattenConsecutive has output size of: torch.Size([5, 80])\n",
            "Linear has output size of: torch.Size([5, 200])\n",
            "BatchNorm1d has output size of: torch.Size([5, 200])\n",
            "Tanh has output size of: torch.Size([5, 200])\n",
            "Linear has output size of: torch.Size([5, 27])\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "    print(f\"{layer.__class__.__name__} has output size of: {(layer.out.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS_V3TsjKs-f"
      },
      "source": [
        "### 3.3.4 - Processing Hierarchically: FlattenConsecutive(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8tWzh33Ks-f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajtdPbQ5Ks-f",
        "outputId": "19230337-9e33-468c-f291-7a1793bc8a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num parameters: 22397\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10\n",
        "# changing the number of hidden units to 68 keeps the same number of parameters as the previous model (22k)\n",
        "n_hidden = 68\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
        "for p in parameters:\n",
        "    p.requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42QK1h5hKs-g",
        "outputId": "adfd09ca-503f-4eb1-9166-4533c3271e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0, 16],\n",
              "        [ 0,  0,  0,  0,  0, 20,  5, 25],\n",
              "        [ 0,  0,  0,  0,  0,  0,  2, 18],\n",
              "        [ 0,  0,  0,  6,  1, 18,  8,  1],\n",
              "        [ 0,  0,  0,  0,  0,  0, 19,  8]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (5,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOfPc4XfKs-g",
        "outputId": "aa2348f1-2b2a-4fc0-eddf-68d84bf315eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding has output size of: torch.Size([5, 8, 10])\n",
            "FlattenConsecutive has output size of: torch.Size([5, 4, 20])\n",
            "Linear has output size of: torch.Size([5, 4, 68])\n",
            "BatchNorm1d has output size of: torch.Size([5, 4, 68])\n",
            "Tanh has output size of: torch.Size([5, 4, 68])\n",
            "FlattenConsecutive has output size of: torch.Size([5, 2, 136])\n",
            "Linear has output size of: torch.Size([5, 2, 68])\n",
            "BatchNorm1d has output size of: torch.Size([5, 2, 68])\n",
            "Tanh has output size of: torch.Size([5, 2, 68])\n",
            "FlattenConsecutive has output size of: torch.Size([5, 136])\n",
            "Linear has output size of: torch.Size([5, 68])\n",
            "BatchNorm1d has output size of: torch.Size([5, 68])\n",
            "Tanh has output size of: torch.Size([5, 68])\n",
            "Linear has output size of: torch.Size([5, 27])\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "    print(f\"{layer.__class__.__name__} has output size of: {layer.out.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBI9i9apKs-g"
      },
      "source": [
        "however, this network gives the same loss = 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbdBmv6TKs-g"
      },
      "source": [
        "### 3.3.5 - Fixing BatchNorm Bug\n",
        "we implemented batchnorm for X 2D only\n",
        "\n",
        "we calculated mean and variance for the first dimension only\n",
        "\n",
        "we don't want to average over the batch dimension only, but also over the 2nd dimension (the 4 groups of 2 characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNYcep8rKs-g",
        "outputId": "c8d09a59-2c59-4727-e10b-0f3ef75f47e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 4, 68])\n",
            "shape of running mean is torch.Size([1, 4, 68])\n"
          ]
        }
      ],
      "source": [
        "e = torch.rand(32, 4, 68)\n",
        "emean = e.mean(dim=(0, 1), keepdim=True)  # (1, 1, 68)\n",
        "evar = e.var((0, 1), keepdim=True)  # (1, 1, 68)\n",
        "ehat = (e - emean) / torch.sqrt(evar + 1e-5)\n",
        "\n",
        "print(ehat.shape)\n",
        "print(f\"shape of running mean is {model.layers[3].running_mean.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZucWdbEGKs-g"
      },
      "outputs": [],
      "source": [
        "class BatchNorm1d:\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "        # buffers (trained while running `momentum update`)\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.training:\n",
        "            # determine the dimension to reduce over\n",
        "            if x.ndim == 2:\n",
        "                dim = 0\n",
        "            elif x.ndim == 3:\n",
        "                dim = (0, 1)\n",
        "\n",
        "            xmean = x.mean(dim, keepdim=True)\n",
        "            # batch variance\n",
        "            xvar = x.var(dim, keepdim=True)\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "\n",
        "        # update the buffers in training\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * \\\n",
        "                    self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * \\\n",
        "                    self.running_var + self.momentum * xvar\n",
        "\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97flZ3zpKs-g",
        "outputId": "d2037861-4e71-49ad-bd03-82b0524dd8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num parameters: 22397\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10\n",
        "# changing the number of hidden units to 68 keeps the same number of parameters as the previous model (22k)\n",
        "n_hidden = 68\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
        "for p in parameters:\n",
        "    p.requires_grad_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmNjkFoKKs-h"
      },
      "source": [
        "The model improves a little bit (2.029 -> 2.022)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eZusvhQKs-h"
      },
      "source": [
        "# 4- Final Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVQlZ3nmKs-h"
      },
      "outputs": [],
      "source": [
        "# Layers made in part 3\n",
        "class Linear:\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn((fan_in, fan_out))\n",
        "        self.weight /= fan_in ** 0.5\n",
        "        self.bias = torch.zeros((fan_out)) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            self.out += self.bias\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "        # buffers (trained while running `momentum update`)\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.training:\n",
        "            # determine the dimension to reduce over\n",
        "            if x.ndim == 2:\n",
        "                dim = 0\n",
        "            elif x.ndim == 3:\n",
        "                dim = (0, 1)\n",
        "\n",
        "            xmean = x.mean(dim, keepdim=True)\n",
        "            # batch variance\n",
        "            xvar = x.var(dim, keepdim=True)\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "\n",
        "        # update the buffers in training\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * \\\n",
        "                    self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * \\\n",
        "                    self.running_var + self.momentum * xvar\n",
        "\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "\n",
        "class Tanh:\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.tanh(x)\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = self.weight[x]\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "\n",
        "class Flatten:\n",
        "    def __call__(self, x):\n",
        "        self.out = x.view((x.shape[0], -1))\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "\n",
        "class Sequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [p for l in self.layers for p in l.parameters()]\n",
        "\n",
        "\n",
        "class FlattenConsecutive:\n",
        "    def __init__(self, n):\n",
        "        # n is the number of consecutive elements we want (2 in our example)\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # in our example: B = 5, T = 8, C = 10\n",
        "        B, T, C = x.shape\n",
        "        # we want to convert X to (5, 4, 20)\n",
        "        x = x.view(B, T // self.n, C * self.n)\n",
        "\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.squeeze(1)\n",
        "\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lusHvp-uKs-h",
        "outputId": "246c3250-98d1-4451-8f26-3eb46ce210cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76579\n"
          ]
        }
      ],
      "source": [
        "n_embd = 24\n",
        "n_hidden = 128\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden,\n",
        "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].weight *= 0.1  # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuGTC6nKKs-h",
        "outputId": "64d4edff-26b0-4f45-98b6-79f4548d118d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.3023\n",
            "  10000/ 200000: 1.7390\n",
            "  20000/ 200000: 1.8811\n",
            "  30000/ 200000: 2.3255\n",
            "  40000/ 200000: 1.6386\n",
            "  50000/ 200000: 1.9138\n",
            "  60000/ 200000: 1.9065\n",
            "  70000/ 200000: 1.6051\n",
            "  80000/ 200000: 1.7464\n",
            "  90000/ 200000: 1.8728\n",
            " 100000/ 200000: 1.5794\n",
            " 110000/ 200000: 1.6545\n",
            " 120000/ 200000: 2.0548\n",
            " 130000/ 200000: 1.5856\n",
            " 140000/ 200000: 1.5998\n",
            " 150000/ 200000: 2.0187\n",
            " 160000/ 200000: 1.8150\n",
            " 170000/ 200000: 1.7204\n",
            " 180000/ 200000: 1.9342\n",
            " 190000/ 200000: 1.5774\n"
          ]
        }
      ],
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "    # minibatch construct\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix]  # batch X,Y\n",
        "\n",
        "    # forward pass\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)  # loss function\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # update: simple SGD\n",
        "    lr = 0.1 if i < 150000 else 0.01  # step learning rate decay\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    # track stats\n",
        "    if i % 10000 == 0:  # print every once in a while\n",
        "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "    lossi.append(loss.log10().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "yFdjhtlgKs-h",
        "outputId": "b1f2c4dd-1b13-4a3f-ae54-91fc55c98d27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a20e6730e50>]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1, keepdim=True).data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiXXpHY3Ks-i"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers:\n",
        "    layer.training = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9WZZvbOKs-i",
        "outputId": "14b22e6d-94cb-4ced-cfc5-3081b36cfb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1.7723759412765503\n",
            "valid 1.9898982048034668\n"
          ]
        }
      ],
      "source": [
        "print(\"train\", split_loss(\"train\"))\n",
        "print(\"valid\", split_loss(\"valid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y97WnKmKs-i",
        "outputId": "c8197f48-57f0-4192-c3d2-cf4f6bce90f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "freer\n",
            "layaani\n",
            "savie\n",
            "pranith\n",
            "ariely\n",
            "deany\n",
            "zackari\n",
            "lauri\n",
            "reyden\n",
            "drekua\n",
            "mihira\n",
            "nihe\n",
            "tajavarus\n",
            "abdulwamina\n",
            "zeara\n",
            "yanah\n",
            "nasi\n",
            "kahera\n",
            "tyair\n",
            "naida\n"
          ]
        }
      ],
      "source": [
        "# sampling from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "        # Forward pass\n",
        "        logits = model(torch.tensor([context]).reshape(1, -1))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        ix = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "        # Shift the Context Window\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "        out.append(ix)\n",
        "\n",
        "    print(\"\".join(itos[i] for i in out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LviTtm4Ks-i"
      },
      "source": [
        "validation loss becomes 1.993"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}