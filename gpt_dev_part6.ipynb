{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shindejayesh987/Neural-Networks-Zero-to-Hero-By-Andrej-Karpathy/blob/main/gpt_dev_part6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR4RkbvY42Lx"
      },
      "source": [
        "# 1- Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqkFFhdN42Lz"
      },
      "source": [
        "## 1.1- Opening and Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYB3TSs742Lz",
        "outputId": "6b4bef6a-3bf1-44b4-d888-372c3f887064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1115393\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/shakespere.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(f\"length of dataset in characters: {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLTrRUvg42L0",
        "outputId": "4e5ea059-1774-4e9d-f611-66a8ff144829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first 1000 characters of dataset:\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"first 1000 characters of dataset:\\n{text[:1000]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAXP1Boq42L0"
      },
      "source": [
        "## 1.2- Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwN3gs1s42L1",
        "outputId": "6c55307d-97de-4f76-fa5e-91bc73f9edb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all chars are:\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"all chars are:{''.join(chars)}\")\n",
        "print(f\"vocab size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UQJ_17F42L1",
        "outputId": "343808cf-ce1d-4d5b-d5f1-7fc2bbc3c66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 43, 50, 50, 53, 6, 1, 61, 53, 56, 50, 42, 2]\n",
            "Hello, world!\n"
          ]
        }
      ],
      "source": [
        "stoi = {ch:i for i, ch in enumerate(chars)}\n",
        "itos = {val:key for key, val in stoi.items()}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "print(encode(\"Hello, world!\"))\n",
        "print(decode(encode(\"Hello, world!\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J66OHV6542L1",
        "outputId": "2663b44e-f1ff-4af6-d3d8-03740e9f0b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: torch.Size([1115393])\n",
            "data type: torch.int64\n",
            "--------------------------------------------------\n",
            "first 100 characters of dataset:\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n",
            "first 100 characters of dataset:\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "\n",
        "print(f\"data shape: {data.shape}\")\n",
        "print(f\"data type: {data.dtype}\")\n",
        "\n",
        "print(\"-\"*50)\n",
        "\n",
        "print(f\"first 100 characters of dataset:\\n{data[:100]}\")\n",
        "print(f\"first 100 characters of dataset:\\n{decode(data[:100].tolist())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9PXwEnG42L1"
      },
      "source": [
        "## 1.3- Train Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpcujCTx42L1"
      },
      "outputs": [],
      "source": [
        "n = int(0.9 * len(data))\n",
        "\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLPB5PPK42L2"
      },
      "source": [
        "## 1.4 Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh5lGQIL42L2",
        "outputId": "4499c9f1-5526-4095-9303-5d2d2b05d879"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ9woGxh42L2",
        "outputId": "6e70a5e7-d642-4027-eb3b-ce0a36e60eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input tensor is [18], target is 47\n",
            "when input tensor is [18, 47], target is 56\n",
            "when input tensor is [18, 47, 56], target is 57\n",
            "when input tensor is [18, 47, 56, 57], target is 58\n",
            "when input tensor is [18, 47, 56, 57, 58], target is 1\n",
            "when input tensor is [18, 47, 56, 57, 58, 1], target is 15\n",
            "when input tensor is [18, 47, 56, 57, 58, 1, 15], target is 47\n",
            "when input tensor is [18, 47, 56, 57, 58, 1, 15, 47], target is 58\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size + 1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t + 1]\n",
        "    target = y[t]\n",
        "    print(f\"when input tensor is {context.tolist()}, target is {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVj1khw642L2",
        "outputId": "6bb5c057-cb49-43b0-a4ad-41c47428f074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "shapetorch.Size([4, 8])\n",
            "data: tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
            "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
            "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
            "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
            "targets:\n",
            "shapetorch.Size([4, 8])\n",
            "data: tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
            "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
            "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
            "        [39,  1, 46, 53, 59, 57, 43,  0]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "# number of input_examples = batch_size * block_size (4 * 8 = 32)\n",
        "\n",
        "def get_batch(split):\n",
        "    # Select the appropriate dataset based on the split parameter\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "\n",
        "    # Generate a batch of random starting indices within the dataset\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "\n",
        "    # Select a block of text of size block_size starting from each random index\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "\n",
        "    # Shift the selected block of text by one character to the right to create the target sequence\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch(\"train\")\n",
        "print(f\"inputs:\\nshape{xb.shape}\\ndata: {xb}\")\n",
        "print(f\"targets:\\nshape{yb.shape}\\ndata: {yb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP_i49jD42L2"
      },
      "source": [
        "# 2- Bigram Language Model\n",
        "simplest language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhDIrxtj42L2",
        "outputId": "5622fa90-f36e-40d2-a862-02f4251eb127"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e2b81742210>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o30WWmc-42L3"
      },
      "source": [
        "## 2.1 Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzou8J5T42L3",
        "outputId": "d93d8cf9-edf4-4058-d921-0ca2500ca4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: torch.Size([32, 65])\n",
            "loss: 4.894842624664307 | we are expecting a loss of around 4.174387454986572\n"
          ]
        }
      ],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a loockup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets = None):\n",
        "        # idx and targets are both (B, T) tensor of ints\n",
        "        logits = self.token_embedding_table(idx) # (B, T, C) = (4, 8 , vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # note that F.cross_entropy accepts inputs in shape (B, C, T)\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T) # can be as targets = targets.view(-1)\n",
        "\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the logits for the next token\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            # (note that we are feeding the whole context each time, however we only care about the last prediction)\n",
        "            # (this make doesn't make sense now, but the function will be modified later)\n",
        "            logits = logits[:, -1, :] # Becomes (B, C) (get the last time step for each sequence)\n",
        "            # apply softmax to convert to probabilities\n",
        "            probs = F.softmax(logits, dim = -1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled token to the context\n",
        "            idx = torch.cat((idx, idx_next), dim = 1) # (B, T + 1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "\n",
        "print(f\"logits shape: {logits.shape}\")\n",
        "print(f\"loss: {loss} | we are expecting a loss of around {torch.log(torch.tensor(vocab_size))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qpZIx0M42L3",
        "outputId": "860f8439-8378-468a-e325-ddcb5bf86711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ],
      "source": [
        "idx = torch.zeros((1,1), dtype = torch.long)\n",
        "generated = m.generate(idx, 100) # shape (1, 101)\n",
        "print(decode(generated[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCai-E1Z42L3"
      },
      "source": [
        "## 2.2- Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS4rufqO42L4",
        "outputId": "880b85ed-cc07-4876-fb2d-8681277b1698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.4699912071228027\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(10000):\n",
        "    # sample a batch of training data\n",
        "    xb, yb = get_batch(\"train\")\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none = True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    lossi.append(loss.item())\n",
        "\n",
        "print(f\"loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "zvjxeGbS42L4",
        "outputId": "4b36fc1e-b7a0-4b3c-fbd6-a9c3b5f09597"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(lossi);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRrb8HOi42L4",
        "outputId": "8f742009-94df-4962-8fde-797556c0f82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iyoteng h hasbe pave pirance\n",
            "Rie hicomyonthar's\n",
            "Plinseard ith henouratucenonthioneir thondy, y heltieiengerofo'dsssit ey\n",
            "KIN d pe wither vouprrouthercc.\n",
            "hathe; d!\n",
            "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
            "h haybet--s n prids, r loncave w hollular s O:\n",
            "HIs; ht anjx?\n",
            "\n",
            "DUThinqunt.\n",
            "\n",
            "LaZAnde.\n",
            "athave l.\n",
            "KEONH:\n",
            "ARThanco be y,-hedarwnoddy scat t tridesar, wnl'shenou\n"
          ]
        }
      ],
      "source": [
        "# sampling from the model\n",
        "idx = torch.zeros((1,1), dtype = torch.long)\n",
        "generated = m.generate(idx, 400) # shape (1, 101)\n",
        "print(decode(generated[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FhjfAT242L4"
      },
      "source": [
        "## 2.3- Porting our code to a script\n",
        "check `bigram.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2n1Bnw442L4"
      },
      "source": [
        "# 3- Self Attention Trick (Averaging the previous tokens embeddings)\n",
        "\n",
        "- we need each token commuinicate with all previous tokens, for example: the 5th token communicate with 1st, 2nd, 3rd, 4th tokens\n",
        "\n",
        "- since we are predicting the next token, we need to consider the previous tokens only\n",
        "\n",
        "- The easiset way to make them communicate is averaging the previous tokens embeddings (it's kinda lossy since we are losing the spatial information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUQJwt8j42L4"
      },
      "source": [
        "## 3.1- Using Explicit loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLOFF-6942L5",
        "outputId": "13f5c2aa-48f6-4878-ac8b-b5a31ac22d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: torch.Size([4, 8, 2])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B, T, C = 4, 8, 2 # batch size, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "print(f\"x shape: {x.shape}\")\n",
        "\n",
        "# We want x[b, t] = mean_(i<=t) x[b, i]\n",
        "xbow = torch.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b, :t+1] # (t, C)\n",
        "        xbow[b, t] = torch.mean(xprev, dim = 0) # average over time dimension (t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQv49aZE42L5",
        "outputId": "35c4225c-b93e-4665-f33b-14c9a976191f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x[0]: tensor([[ 0.1808, -0.0700],\n",
            "        [-0.3596, -0.9152],\n",
            "        [ 0.6258,  0.0255],\n",
            "        [ 0.9545,  0.0643],\n",
            "        [ 0.3612,  1.1679],\n",
            "        [-1.3499, -0.5102],\n",
            "        [ 0.2360, -0.2398],\n",
            "        [-0.9211,  1.5433]])\n",
            "xbow[0]: tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n",
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ]
        }
      ],
      "source": [
        "# Let's Check the first Batch\n",
        "print(f\"x[0]: {x[0]}\")\n",
        "print(f\"xbow[0]: {xbow[0]}\")\n",
        "\n",
        "# the first row is the same\n",
        "print(x[0, 0] == xbow[0, 0])\n",
        "# the second row is the average of the first two rows\n",
        "print((x[0, 0] + x[0, 1]) / 2 == xbow[0, 1])\n",
        "# etc ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3R0ZKrv42L5"
      },
      "source": [
        "## 3.2- Using Matrix Multiplication\n",
        "- instead of nested loops, we can make it using matrix multiplication\n",
        "- This can be done by multiplying the matrix with lower triangular matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BUMldgD42L5",
        "outputId": "32b5b1dc-001a-4076-c13c-c39ca0ffa496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a (shape = torch.Size([3, 3])) =\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "b (shape = torch.Size([3, 2])) =\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "c (shape = torch.Size([3, 2])) =\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "torch.manual_seed(42)\n",
        "# lower triangular matrix of ones\n",
        "a = torch.tril(torch.ones(3,3))\n",
        "# make all rows sum to 1\n",
        "a = a / torch.sum(a, 1, keepdim = True)\n",
        "# create a random matrix\n",
        "b = torch.randint(0, 10, (3, 2)).float()\n",
        "\n",
        "c = a @ b\n",
        "print(f\"a (shape = {a.shape}) =\\n{a}\")\n",
        "print(f\"b (shape = {b.shape}) =\\n{b}\")\n",
        "print(f\"c (shape = {c.shape}) =\\n{c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUvfkiOO42L6",
        "outputId": "0f2eb636-9099-4705-bf39-763a61493039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# We want x[b, t] = mean_(i<=t) x[b, i]\n",
        "wei = torch.tril(torch.ones(T, T)) # (T, T)\n",
        "# make all rows sum to 1\n",
        "wei = wei / torch.sum(wei, 1, keepdim = True) # (T, T)\n",
        "xbow2 = wei @ x # (T, T) @ (B, T, C) ----broadcasting----> (B, T, T) @ (B, T, C)  (B, T, C)\n",
        "\n",
        "# check if xbow2 is the same as xbow\n",
        "print(torch.allclose(xbow, xbow2, atol = 1e-7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXX4D4jM42L7"
      },
      "source": [
        "## 3.3- Using Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwsLcuGn42L7",
        "outputId": "2d3974df-14c4-4bd9-b981-eb0948519cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wei:\n",
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "wei:\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "# we start with zeros, but later these will be replaced with data dependent values (affinities)\n",
        "wei = torch.zeros((T, T))\n",
        "# masked_fill: for all elements where tril == 0, replace with float(\"-inf\")\n",
        "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
        "print(f\"wei:\\n{wei}\")\n",
        "wei = F.softmax(wei, dim = -1)\n",
        "print(f\"wei:\\n{wei}\")\n",
        "xbow3 = wei @ x\n",
        "\n",
        "# check if xbow3 is the same as xbow\n",
        "print(torch.allclose(xbow, xbow3, atol = 1e-7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XEYyYXQ42L8"
      },
      "source": [
        "# 4- Minor Code Cleanup\n",
        "(these modifications are done in `bigram.py`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEiaXr3Z42L8"
      },
      "source": [
        "## 4.1- Adding variable embedding size\n",
        "1. removing vocab_size from the constructor of `BigramLanguageModel` class, since it's already defiend above\n",
        "2. Modifying the embedding layer to has an output size of `n_embed` instead of `vocab_size`\n",
        "3. Adding a linear layer with `vocab_size` outputs after the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMBo_qry42L8"
      },
      "outputs": [],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    # no need to pass vocab_size as an argument, since it is a global variable in this file\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a loockup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        # the output layer is a linear layer with vocab_size outputs\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets = None):\n",
        "        # idx and targets are both (B, T) tensor of ints\n",
        "        token_emb = self.token_embedding_table(idx) # (B, T, C) = (4, 8 , vocab_size)\n",
        "        logits = self.lm_head(token_emb) # (B, T, vocab_size) = (4, 8, vocab_size)\n",
        "\n",
        "    # rest of the code .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjukBGCx42L8"
      },
      "source": [
        "## 4.2- Positional Encoding\n",
        "1. Adding a positional encoding layer to the model `self.position_embedding_table`\n",
        "2. Adding the positional encoding to the input embeddings `x = token_emb + pos_emb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZEfzhFT42L9"
      },
      "outputs": [],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    # no need to pass vocab_size as an argument, since it is a global variable in this file\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a loockup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        # each position is also associated with an embedding vector\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        # the output layer is a linear layer with vocab_size outputs\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets = None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B, T) tensor of ints\n",
        "        token_emb = self.token_embedding_table(idx) # (B, T, C) = (4, 8 , vocab_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device = idx.device)) # (T, C) = (8, vocab_size)\n",
        "        # x has the token identities + the position embeddings\n",
        "        x = token_emb + pos_emb # (B, T, C) = (4, 8, vocab_size)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) = (4, 8, vocab_size)\n",
        "\n",
        "    # rest of the code .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRXEu-UY42L9"
      },
      "source": [
        "# 5- Self Attention\n",
        "Consider his as `version 4 ` of part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pokR7w3F42L-"
      },
      "source": [
        "## 5.1- Previous code from part 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39w6-iNc42L-",
        "outputId": "3a13c723-a1ca-4dfc-d481-5080869f17ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tril:\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "wei:\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "out.shape:\n",
            "torch.Size([4, 8, 32])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B, T, C = 4, 8, 32 # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
        "wei = F.softmax(wei, dim = -1)\n",
        "\n",
        "out = wei @ x\n",
        "\n",
        "print(f\"tril:\\n{tril}\")\n",
        "print(f\"wei:\\n{wei}\")\n",
        "print(f\"out.shape:\\n{out.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28bGzzWs42L-"
      },
      "source": [
        "## 5.2- Building the Self-Attention\n",
        "each token (can be called node too) at each position emmits 2 vectors:\n",
        "1. Query: What I'm looking for?\n",
        "2. Key: What do I contain?\n",
        "3. Value: What I will tell you or the information I have `in this head`?\n",
        "    \n",
        "- affinities between tokens `wei` = my Query @ all Keys\n",
        "- if key and query are aligned  high value  learn more about this sequence\n",
        "- instead of multiplying wei with tokens directly, we multiply it with values (which is the information we want to learn about)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wK9Bjzs42L-",
        "outputId": "2cd19374-88cf-4550-b5f5-a41a75219d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wei[0]: tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
            "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
            "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B, T, C = 4, 8, 32 # batch, time, channels\n",
        "\n",
        "# x is private information of each token\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "# single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias = False)\n",
        "query = nn.Linear(C, head_size, bias = False)\n",
        "value = nn.Linear(C, head_size, bias = False)\n",
        "\n",
        "\n",
        "k = key(x) # (B, T, head_size) = (4, 8, 16)\n",
        "q = query(x) # (B, T, head_size) = (4, 8, 16)\n",
        "\n",
        "# now every token in every batch is associated with a key and a query (in parallel), no communication between tokens has happened yet\n",
        "\n",
        "wei = q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) = (B, T, T)\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "# wei are no longer zeros, but data dependent values (affinities)\n",
        "# wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
        "wei = F.softmax(wei, dim = -1)\n",
        "\n",
        "print(f\"wei[0]: {wei[0]}\")\n",
        "\n",
        "# multiply with value instead of x\n",
        "v = value(x) # (B, T, head_size) = (4, 8, 16)\n",
        "out = wei @ v # (B, T, T) @ (B, T, head_size) = (B, T, head_size)\n",
        "# out = wei @ x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CjxHQCU42L-"
      },
      "source": [
        "## 5.3- Notes About Self Attention\n",
        "\n",
        "1. Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "\n",
        "2. There is no notion of space. Attention simply acts over a set of vectors. **This is why we need to positionally encode tokens.**\n",
        "\n",
        "3. Each example across batch dimension is of course processed completely **independently** and **never \"talk\" to each other**\n",
        "\n",
        "4. In an `encoder` attention block just delete the single line that does masking with `tril`, **allowing all tokens to communicate**, it can be used for some applications like translation and sentiment analysis. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like **language modeling**.\n",
        "\n",
        "5. `self-attention` just means that the **keys** and **values** are **produced from the same source** as **queries**. In \"cross-attention\", the **queries** still get produced from **x**, but the **keys** and **values** come from some other, external source (e.g. an **encoder** module)\n",
        "\n",
        "6. `Scaled Dot-Product Attention`: $\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$\n",
        "\n",
        "    `Scaled` attention additional divides `wei` by $\\frac{1}{\\sqrt{\\text{head\\_size}}}$. This makes it so when input `Q`, `K` are unit variance, `wei` will be **unit variance** too and Softmax will stay diffuse and **not saturate** too much. it's important especially in initialization.\n",
        "\n",
        "    if the **variance** is **very high**, **softmax** will **converge** to **one-hot vector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9o6_u8d42L_",
        "outputId": "135b966a-0ac8-437f-dad6-ffe7652bd744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unscaled Attention\n",
            "var(k) = 1.044861912727356\n",
            "var(q) = 1.0700464248657227\n",
            "var(wei) = 17.46897315979004\n",
            "\n",
            "Scaled Attention\n",
            "var(k) = 1.044861912727356\n",
            "var(q) = 1.0700464248657227\n",
            "var(wei) = 1.0918108224868774\n"
          ]
        }
      ],
      "source": [
        "# Scaled Attention\n",
        "k = torch.randn(B, T, head_size)\n",
        "q = torch.randn(B, T, head_size)\n",
        "\n",
        "print(\"Unscaled Attention\")\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "print(f\"var(k) = {torch.var(k)}\")\n",
        "print(f\"var(q) = {torch.var(q)}\")\n",
        "print(f\"var(wei) = {torch.var(wei)}\")\n",
        "\n",
        "print(\"\\nScaled Attention\")\n",
        "wei = q @ k.transpose(-2, -1) * (head_size ** -0.5)\n",
        "print(f\"var(k) = {torch.var(k)}\")\n",
        "print(f\"var(q) = {torch.var(q)}\")\n",
        "print(f\"var(wei) = {torch.var(wei)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUpKJwqY42L_"
      },
      "source": [
        "## 5.4- Adding single Self Attention Head to the Bigram Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-f8j8dV42L_"
      },
      "source": [
        "### 5.4.1- Making new `Head` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9P-JWGm42L_"
      },
      "outputs": [],
      "source": [
        "# Making the Head Class\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias = False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias = False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias = False)\n",
        "        # since tril isn't a parameter, we register it as a buffer\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        q = self.query(x) # (B, T, C)\n",
        "\n",
        "        # compute attention scores (affinities)\n",
        "        wei = q @ k.transpose(-2, -1) * (C ** -0.5) # (B, T, C) @ (B, C, T) = (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0 , float(\"-inf\")) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim = -1) # (B, T, T)\n",
        "\n",
        "        # perform weighted aggregation of the values\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) = (B, T, C)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdKE7WUe42L_"
      },
      "source": [
        "### 5.4.2- Modifying `BigramLanguageModel` class\n",
        "1. Adding `Head` to the `BigramLanguageModel` class\n",
        "2. Adding `Head` to the `BigramLanguageModel` forward pass\n",
        "3. for `generate` function, we need crop idx to keep `idx.shape <= block_size`, since we are using `positional embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmSvVr0n42L_"
      },
      "outputs": [],
      "source": [
        "# Adding Head to the BigramLanguageModel\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    # no need to pass vocab_size as an argument, since it is a global variable in this file\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a loockup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        # each position is also associated with an embedding vector\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        # a single head of self attention\n",
        "        self.sa_head = Head(n_embed)\n",
        "        # the output layer is a linear layer with vocab_size outputs\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets = None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B, T) tensor of ints\n",
        "        token_emb = self.token_embedding_table(idx) # (B, T, C) = (4, 8 , vocab_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device = idx.device)) # (T, C) = (8, vocab_size)\n",
        "        # x has the token identities + the position embeddings\n",
        "        x = token_emb + pos_emb # (B, T, C) = (4, 8, vocab_size)\n",
        "        # feed the input to the self attention head\n",
        "        x = self.sa_head(x) # (B, T, C) = (4, 8, vocab_size)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) = (4, 8, vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # note that F.cross_entropy accepts inputs in shape (B, C, T)\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T) # can be as targets = targets.view(-1)\n",
        "\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:] # (B, T)\n",
        "            # get the logits for the next token\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            # (note that we are feeding the whole context each time, however we only care about the last prediction)\n",
        "            # (this make doesn't make sense now, but the function will be modified later)\n",
        "            logits = logits[:, -1, :] # Becomes (B, C) (get the last time step for each sequence)\n",
        "            # apply softmax to convert to probabilities\n",
        "            probs = F.softmax(logits, dim = -1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled token to the context\n",
        "            idx = torch.cat((idx, idx_next), dim = 1) # (B, T + 1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqH-HcmI42L_"
      },
      "source": [
        "### 5.4.3- Testing\n",
        "(loss is `2.54` instead of `2.57`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ROqpzV42MA"
      },
      "source": [
        "## 5.5- Multi-Head Attention\n",
        "- make the new `MultiHeadAttention` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yOopy7a42MA"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_head, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_head)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # concatenate them into the channel dimension\n",
        "        return torch.cat([h(x) for h in self.heads], dim = -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqkS71K742MA"
      },
      "source": [
        "then add it to `BigramLanguageModel` class\n",
        "\n",
        "previously:\n",
        "```python\n",
        "self.sa_head = Head(n_embed)\n",
        "```\n",
        "now:\n",
        "```python\n",
        "self.sa_heads = MultiHeadAttention(num_head = 4, head_size = n_embed // 4)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-93FNeH42MA"
      },
      "source": [
        "### 5.5.1- Testing\n",
        "(loss is `2.51` instead of `2.54`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5wiQFOX42MA"
      },
      "source": [
        "# 6- Adding FeedForward Layer\n",
        "the feedforward is applied to each token independently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeWhT8Zx42MA"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embed, n_embed),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEFSZr2c42MB"
      },
      "source": [
        "# then add it to forward of the BigramLanguageModel\n",
        "``` python\n",
        "# previous code ..\n",
        "x = self.sa_heads(x) # (B, T, C) = (4, 8, vocab_size)\n",
        "# feed the output of the self attention head to the feed forward layer\n",
        "x = self.ff(x) # (B, T, C) = (4, 8, vocab_size)\n",
        "logits = self.lm_head(x) # (B, T, vocab_size) = (4, 8, vocab_size)\n",
        "# rest of the code ..\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PW7aOGh42MB"
      },
      "source": [
        "## 6.1- Test\n",
        "(loss is `2.46` instead of `2.51`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaQg9VhM42MB"
      },
      "source": [
        "# 7- Residual Connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh9rfEHe42MB"
      },
      "source": [
        "## 7.1 Stacking the Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fbcKizy42MB"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer Block: Communication followed by Computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed, n_head):\n",
        "        \"\"\" n_embed: embedding dimension\n",
        "            n_head: number of heads in the multi-head attention\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa(x)\n",
        "        x = self.ffwd(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbWZENsf42MB"
      },
      "source": [
        "``` python\n",
        "# previous code ..\n",
        "# each token directly reads off the logits for the next token from a loockup table\n",
        "self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "# each position is also associated with an embedding vector\n",
        "self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "# transformer blocks\n",
        "self.blocks = nn.Sequential(\n",
        "        Block(n_embed, n_head = 4),\n",
        "        Block(n_embed, n_head = 4),\n",
        "        Block(n_embed, n_head = 4),\n",
        ")\n",
        "self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "# rest of the code ..\n",
        "```\n",
        "\n",
        "add them in the forward pass\n",
        "``` python\n",
        "# previous code ..\n",
        "x = token_emb + pos_emb # (B, T, C) = (4, 8, vocab_size)\n",
        "# feed the input to the self attention head\n",
        "x = self.blocks(x) # (B, T, C) = (4, 8, vocab_size)\n",
        "logits = self.lm_head(x) # (B, T, vocab_size) = (4, 8, vocab_size)\n",
        "# rest of the code ..\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf4xHvkk42MB"
      },
      "source": [
        "### 7.1.1 Test\n",
        "(loss is `2.81` instead of `2.46`)  **WORSE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FAjWgLa42MC"
      },
      "source": [
        "## 7.2 - Adding Residual Connections (Skip Connections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4KqxrbH42MC"
      },
      "source": [
        "### 7.2.1- Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PNIyUX042MC"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer Block: Communication followed by Computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed, n_head):\n",
        "        \"\"\" n_embed: embedding dimension\n",
        "            n_head: number of heads in the multi-head attention\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual connection (add the input to the output)\n",
        "        x = x + self.sa(x)\n",
        "        x = x + self.ffwd(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6ljumU542MC"
      },
      "source": [
        "### 7.2.2- Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcx3BtUH42MC"
      },
      "outputs": [],
      "source": [
        "# Multi Head Attention Class\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_head, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_head)])\n",
        "        # linear transformation to the output of the multi-head attention as projection back to the residual pathway\n",
        "        self.proj = nn.Linear(n_embed, n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out is the outptu of the multi-head attention\n",
        "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
        "        # apply a linear layer to the concatenated output\n",
        "        out = self.proj(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUSsIuz42MC"
      },
      "source": [
        "### 7.2.3- FeedForward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi01Zfug42MC"
      },
      "outputs": [],
      "source": [
        "# Feed Forward Class\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # multiply by 4 to follow the original implementation\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_embed * 4, n_embed),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HszTKtM42MC"
      },
      "source": [
        "### 7.2.4 Test\n",
        "(loss is `2.33` instead of `2.81` and `2.46` before it)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LW42_UI42MC"
      },
      "source": [
        "# 8- LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tp9KZRV42MC"
      },
      "source": [
        "## 8.1- BatchNorm1d from makemore part 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4_t7bQN42MD",
        "outputId": "7b4e5727-6edb-499f-b272-7bd1ac77cd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean of first column: 0.0000 | std of first column: 1.0000\n",
            "mean of first row: 0.0411 | std of first row: 1.0431\n"
          ]
        }
      ],
      "source": [
        "class BatchNorm1d:\n",
        "    def __init__(self, dim, eps=1e-5, momentum = 0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "        # buffers (trained while running `momentum update`)\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.training:\n",
        "            # batch mean\n",
        "            xmean = x.mean(0, keepdim= True)\n",
        "            # batch variance\n",
        "            xvar = x.var(0, keepdim= True)\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "\n",
        "        # update the buffers in training\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = BatchNorm1d(100)\n",
        "x = torch.randn(32, 100)\n",
        "x = module(x)\n",
        "x.shape\n",
        "\n",
        "# columns are normalized\n",
        "print(f\"mean of first column: {x[:, 0].mean():.4f} | std of first column: {x[:, 0].std():.4f}\")\n",
        "# rows are not normalized  we need to normalize the rows instead\n",
        "print(f\"mean of first row: {x[0, :].mean():.4f} | std of first row: {x[0, :].std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br3QClp442MD",
        "outputId": "05f6eb68-6f43-4baa-d6ce-60031b1be9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean of first column: 0.1469 | std of first column: 0.8803\n",
            "mean of first row: -0.0000 | std of first row: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# after normalizing the rows (and removing the buffers too)\n",
        "class BatchNorm1d:\n",
        "    def __init__(self, dim, eps=1e-5, momentum = 0.1):\n",
        "        self.eps = eps\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        xmean = x.mean(1, keepdim= True)\n",
        "        xvar = x.var(1, keepdim= True)\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = BatchNorm1d(100)\n",
        "x = torch.randn(32, 100)\n",
        "x = module(x)\n",
        "x.shape\n",
        "\n",
        "# columns are not normalized now\n",
        "print(f\"mean of first column: {x[:, 0].mean():.4f} | std of first column: {x[:, 0].std():.4f}\")\n",
        "# rows are normalized now\n",
        "print(f\"mean of first row: {x[0, :].mean():.4f} | std of first row: {x[0, :].std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO04IdXD42MD"
      },
      "source": [
        "## 8.2- Adding LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKbN7BLV42MD"
      },
      "source": [
        "### 8.2.1- in the transformer blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uad6oKpZ42MD"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer Block: Communication followed by Computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed, n_head):\n",
        "        \"\"\" n_embed: embedding dimension\n",
        "            n_head: number of heads in the multi-head attention\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embed)\n",
        "        # ln1 is applied directly on input before the multi-head attention\n",
        "        self.ln1 = nn.LayerNorm(n_embed)\n",
        "        # ln2 is applied directly on the output of the multi-head attention before the feed-forward layer\n",
        "        self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual connection (add the input to the output)\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrIsJjEL42MD"
      },
      "source": [
        "### 8.2.1- after all blocks (before last linear layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ93bFcE42MD"
      },
      "outputs": [],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    # no need to pass vocab_size as an argument, since it is a global variable in this file\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a loockup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        # each position is also associated with an embedding vector\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "                Block(n_embed, n_head = 4),\n",
        "                Block(n_embed, n_head = 4),\n",
        "                Block(n_embed, n_head = 4),\n",
        "                # add layernorm here\n",
        "                nn.LayerNorm(n_embed),\n",
        "        )\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBtWWdNJ42MD"
      },
      "source": [
        "# 9- Scaling up the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUBEsBQY42MD"
      },
      "source": [
        "## 9.1- Adding `n_layer` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uyLCWZX42MD"
      },
      "outputs": [],
      "source": [
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    # no need to pass vocab_size as an argument, since it is a global variable in this file\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a loockup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        # each position is also associated with an embedding vector\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(*[Block(n_embed, n_head = 4) for _ in range(n_layer)])\n",
        "        # Remember to add it in forward too\n",
        "        self.ln_f = nn.LayerNorm(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkE2XUwR42ME"
      },
      "source": [
        "## 9.2- Adding Dropouts\n",
        "- in `Head` after calculating `wei`\n",
        "- in `MultiHeadAttention` after `self.proj`\n",
        "- in `FeedForward` after last linear"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}